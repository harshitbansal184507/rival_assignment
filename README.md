# API Log Analyzer

A comprehensive serverless function for analyzing API usage patterns, detecting performance issues, providing cost optimization insights and caching opportunities.

## ðŸ“‹ Project Overview

This project analyzes API call logs to generate detailed analytics including:

- **Summary Statistics**: Total requests, time ranges, average response times, error rates
- **Endpoint Analytics**: Per-endpoint performance metrics and statistics
- **Performance Issue Detection**: Identifies slow endpoints and high error rates
- **Cost Analysis**: Estimates serverless compute costs with optimization potential
- **Caching Opportunities**: Identifies endpoints that would benefit from caching
- **Actionable Recommendations**: Suggests improvements based on data patterns

### Key Features

âœ… Processes 1,00,000+ logs in under 2 seconds  
âœ… Handles edge cases gracefully (invalid data, missing fields, etc.)  
âœ… 80%+ test coverage  
âœ… Production-ready error handling  
âœ… Comprehensive documentation

---

## ðŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)

### Installation

1. **Clone the repository**

```bash
git clone <your-repo-url>
cd rival-assignment
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Verify installation**

```bash
python test.py
```

---

## ðŸ’» Usage

### Basic Usage

```python
from main import analyze_api_logs
import json

# Load your log data
with open('logs.json', 'r') as f:
    logs = json.load(f)

# Analyze the logs
result = analyze_api_logs(logs)

# Access results
print(f"Total Requests: {result['summary']['total_requests']}")
print(f"Average Response Time: {result['summary']['avg_response_time_ms']}ms")
print(f"Error Rate: {result['summary']['error_rate_percentage']}%")
```

### Input Format

Each log entry should have the following structure:

```json
{
  "timestamp": "2025-01-15T10:30:00Z",
  "endpoint": "/api/users",
  "method": "GET",
  "response_time_ms": 245,
  "status_code": 200,
  "user_id": "user_123",
  "request_size_bytes": 512,
  "response_size_bytes": 2048
}
```

### Output Format

The function returns a comprehensive analysis:

```json
{
  "summary": {
    "total_requests": 1000,
    "time_range": {
      "start": "2025-01-15T10:00:00Z",
      "end": "2025-01-15T11:00:00Z"
    },
    "avg_response_time_ms": 189.5,
    "error_rate_percentage": 2.3
  },
  "endpoint_stats": [...],
  "performance_issues": [...],
  "recommendations": [...],
  "hourly_distribution": {...},
  "top_users_by_requests": [...],
  "cost_analysis": {...},
  "caching_opportunities": [...],

}
```

### Command Line Usage

```bash
# Run with a sample dataset
python test.py

# Or use it as a module
python -c "from main import analyze_api_logs; import json; \
  logs = json.load(open('tests/test_data/sample_large.json')); \
  print(analyze_api_logs(logs)['summary'])"
```

---

## ðŸ§ª Running Tests

### Run All Tests

```bash
# Run complete test suite
pytest tests/ -v

# With coverage report
pytest tests/ --cov=main --cov=analytics --cov=utils --cov=config --cov-report=html
```

### Run Individual Test Files

```bash
# Unit tests
pytest tests/unit_tests.py -v

# Edge cases
pytest tests/test_edge_cases.py -v

# Performance tests
pytest tests/performance_test.py -v -s

# Integration tests
pytest tests/integration_tests.py -v -s
```

### Test Coverage

The project includes comprehensive tests covering:

- âœ… **Unit Tests** (20+ tests): Core functionality
- âœ… **Edge Cases** (19+ tests): Invalid inputs, missing fields, boundary conditions
- âœ… **Performance Tests**: 1,00,000+ logs processed in < 2 seconds
- âœ… **Integration Tests**: Real-world datasets

**Current Coverage: 85%+**

View detailed coverage report:

```bash
pytest tests/ --cov=main --cov=analytics --cov=utils --cov=config --cov-report=html
open htmlcov/index.html
```

---

## ðŸ“Š Performance

### Time Complexity

| Operation           | Complexity     | Notes                                |
| ------------------- | -------------- | ------------------------------------ |
| Overall Analysis    | O(n)           | Where n = number of logs             |
| Summary Calculation | O(n)           | Single pass through logs             |
| Endpoint Stats      | O(n)           | Group by endpoint, single pass       |
| Performance Issues  | O(e)           | Where e = number of endpoints        |
| Hourly Distribution | O(n)           | Single pass with timestamp parsing   |
| Top Users           | O(n + u log u) | Where u = unique users               |
| Cost Analysis       | O(n + e)       | Process logs + aggregate by endpoint |
| Caching Analysis    | O(n + e)       | Group and analyze endpoints          |

**Overall: O(n)** - Linear time complexity

### Space Complexity

| Component         | Complexity | Notes                            |
| ----------------- | ---------- | -------------------------------- |
| Input Storage     | O(n)       | Original log data                |
| Endpoint Grouping | O(n)       | Worst case: all unique endpoints |
| Time Windows      | O(w)       | Number of time windows analyzed  |
| Output            | O(e + u)   | Endpoints + users in results     |

**Overall: O(n)** - Linear space complexity

## ðŸ“ Project Structure

```
rival-assignment/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ DESIGN.md              # Design decisions and approach
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .gitignore            # Git ignore rules
â”‚
â”œâ”€â”€ main.py               # Main analysis function
â”œâ”€â”€ analytics.py          # Analysis helper functions
â”œâ”€â”€ config.py             # Configuration constants
â”œâ”€â”€ utils.py              # Utility functions
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ unit_tests.py              # Unit tests
    â”œâ”€â”€ test_edge_cases.py         # Edge case tests
    â”œâ”€â”€ performance_test.py        # Performance tests
    â”œâ”€â”€ integration_tests.py       # Integration tests
    â”œâ”€â”€ test.py                    # Quick smoke test
    â””â”€â”€ test_data/
        â”œâ”€â”€ sample_test_data_small.json
        â”œâ”€â”€ sample_medium.json
        â”œâ”€â”€ sample_large.json
        â””â”€â”€ generate_dataset.py
```

---

## ðŸ”§ Configuration

Edit `config.py` to customize thresholds

---

## ðŸ“š API Reference

### Main Function

```python
def analyze_api_logs(logs: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Analyze API logs and generate comprehensive analytics.

    Args:
        logs: List of API log entries

    Returns:
        Dictionary containing analysis results

    Raises:
        ValueError: If logs is not a list
    """
```

### Key Output Fields

| Field                   | Type | Description                  |
| ----------------------- | ---- | ---------------------------- |
| `summary`               | dict | Overall statistics           |
| `endpoint_stats`        | list | Per-endpoint metrics         |
| `performance_issues`    | list | Detected issues              |
| `recommendations`       | list | Actionable suggestions       |
| `cost_analysis`         | dict | Cost breakdown and estimates |
| `caching_opportunities` | list | Endpoints to cache           |

---

## ðŸŽ¯ Features in Detail

### 1. Performance Issue Detection

Automatically identifies:

- **Slow Endpoints**: Response time > 500ms (configurable)
- **High Error Rates**: Error rate > 5% (configurable)
- **Severity Levels**: Critical, High, Medium

### 2. Cost Analysis

Calculates costs based on:

- Request count
- Execution time (per millisecond)
- Memory usage (based on response size)
- Provides optimization potential estimate

### 3. Caching Opportunities

Identifies endpoints suitable for caching based on:

- High request frequency (> 100 requests)
- Majority GET requests (> 80%)
- Low error rate (< 2%)
- Estimates cost savings and cache hit rates

## ðŸ› Error Handling

The function gracefully handles:

âœ… Empty input arrays  
âœ… Single log entries  
âœ… Missing required fields  
âœ… Invalid timestamp formats  
âœ… Negative values  
âœ… Invalid status codes  
âœ… Mixed valid/invalid data

Invalid entries are filtered out and processing continues with valid data.

---

## ðŸ¤ Contributing

### Code Style

- Follow PEP 8 guidelines
- Use type hints
- Add docstrings to all functions
- Write tests for new features

## ðŸ“„ License

This project is part of the Rival.io internship assignment.

---

## ðŸ“ž Contact

For questions or issues, contact: harshitbansal184507@gmail.com

---

## ðŸ™ Acknowledgments

- Assignment provided by Rival.io
- Built as part of the Software Development Internship application

---

## ðŸ“ˆ Future Enhancements

Potential improvements:

- [ ] Real-time streaming analysis
- [ ] Machine learning-based anomaly detection
- [ ] GraphQL endpoint support
- [ ] Custom alerting rules
- [ ] Dashboard visualization
- [ ] Export to multiple formats (CSV, Excel, PDF)

---

**Version**: 1.0.0  
**Last Updated**: January 2025  
**Python Version**: 3.8+
